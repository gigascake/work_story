{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbcf08b4-c712-4767-92bf-4f3ada35a3d8",
   "metadata": {},
   "source": [
    "- 신경망은 데이터에 대한 작업을 수행하는 계층/모듈로 구성된다.\n",
    "- torch.nn 네임 스페이스는 자신의 신경망을 구축하는 데 필요한 모든 빌딩 블록을 제공합니다.\n",
    "- Every module in PyTorch subclasses the nn.Module.\n",
    "- 신경망은 다른 모듈(레이어)로 구성된 모듈 그 자체이다.\n",
    "- 이러한 중첩된 구조를 통해 복잡한 아키텍처를 쉽게 구축하고 관리할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d492b9b-d3d5-4abd-92a4-0857540f67b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "885f9ed9-964b-4fea-bd96-31db7a21f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_obj = torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16af4d38-b156-4f2a-ba65-ff66b500fc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Any',\n",
       " 'BFloat16Storage',\n",
       " 'BFloat16Tensor',\n",
       " 'BoolStorage',\n",
       " 'BoolTensor',\n",
       " 'ByteStorage',\n",
       " 'ByteTensor',\n",
       " 'CharStorage',\n",
       " 'CharTensor',\n",
       " 'ComplexDoubleStorage',\n",
       " 'ComplexFloatStorage',\n",
       " 'CudaError',\n",
       " 'DeferredCudaCallError',\n",
       " 'Device',\n",
       " 'Dict',\n",
       " 'DoubleStorage',\n",
       " 'DoubleTensor',\n",
       " 'Event',\n",
       " 'FloatStorage',\n",
       " 'FloatTensor',\n",
       " 'HalfStorage',\n",
       " 'HalfTensor',\n",
       " 'IntStorage',\n",
       " 'IntTensor',\n",
       " 'List',\n",
       " 'LongStorage',\n",
       " 'LongTensor',\n",
       " 'Optional',\n",
       " 'ShortStorage',\n",
       " 'ShortTensor',\n",
       " 'Stream',\n",
       " 'Tuple',\n",
       " 'Union',\n",
       " '_CudaBase',\n",
       " '_CudaDeviceProperties',\n",
       " '_Graph',\n",
       " '_StorageBase',\n",
       " '__annotations__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_check_capability',\n",
       " '_check_cubins',\n",
       " '_cudart',\n",
       " '_device',\n",
       " '_device_t',\n",
       " '_dummy_type',\n",
       " '_get_device_index',\n",
       " '_initialization_lock',\n",
       " '_initialized',\n",
       " '_is_in_bad_fork',\n",
       " '_lazy_call',\n",
       " '_lazy_init',\n",
       " '_lazy_new',\n",
       " '_queued_calls',\n",
       " '_sleep',\n",
       " '_tls',\n",
       " '_utils',\n",
       " 'amp',\n",
       " 'caching_allocator_alloc',\n",
       " 'caching_allocator_delete',\n",
       " 'can_device_access_peer',\n",
       " 'check_error',\n",
       " 'collections',\n",
       " 'contextlib',\n",
       " 'cudaStatus',\n",
       " 'cudart',\n",
       " 'current_blas_handle',\n",
       " 'current_device',\n",
       " 'current_stream',\n",
       " 'default_generators',\n",
       " 'default_stream',\n",
       " 'device',\n",
       " 'device_count',\n",
       " 'device_of',\n",
       " 'empty_cache',\n",
       " 'get_arch_list',\n",
       " 'get_device_capability',\n",
       " 'get_device_name',\n",
       " 'get_device_properties',\n",
       " 'get_gencode_flags',\n",
       " 'get_rng_state',\n",
       " 'get_rng_state_all',\n",
       " 'has_half',\n",
       " 'has_magma',\n",
       " 'init',\n",
       " 'initial_seed',\n",
       " 'ipc_collect',\n",
       " 'is_available',\n",
       " 'is_initialized',\n",
       " 'list_gpu_processes',\n",
       " 'manual_seed',\n",
       " 'manual_seed_all',\n",
       " 'max_memory_allocated',\n",
       " 'max_memory_cached',\n",
       " 'max_memory_reserved',\n",
       " 'memory',\n",
       " 'memory_allocated',\n",
       " 'memory_cached',\n",
       " 'memory_reserved',\n",
       " 'memory_snapshot',\n",
       " 'memory_stats',\n",
       " 'memory_stats_as_nested_dict',\n",
       " 'memory_summary',\n",
       " 'nccl',\n",
       " 'nvtx',\n",
       " 'os',\n",
       " 'profiler',\n",
       " 'random',\n",
       " 'reset_accumulated_memory_stats',\n",
       " 'reset_max_memory_allocated',\n",
       " 'reset_max_memory_cached',\n",
       " 'reset_peak_memory_stats',\n",
       " 'seed',\n",
       " 'seed_all',\n",
       " 'set_device',\n",
       " 'set_per_process_memory_fraction',\n",
       " 'set_rng_state',\n",
       " 'set_rng_state_all',\n",
       " 'sparse',\n",
       " 'stream',\n",
       " 'streams',\n",
       " 'synchronize',\n",
       " 'threading',\n",
       " 'torch',\n",
       " 'traceback',\n",
       " 'warnings']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(cuda_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f04c944c-79a2-4f45-b6d9-f1457c63b5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPU:0\\nno processes are running'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_obj.list_gpu_processes()\n",
    "## pip install pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "540f16ee-49f8-423c-8694-4cccb03ccf0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPU:0\\nno processes are running'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_obj.list_gpu_processes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf89a97e-2202-4609-9ccb-ecb3919c9758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_obj.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d642b038-7679-4439-904a-45be19179072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 3090'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_obj.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb57bebb-fdb3-44e2-95b9-53b7302594b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 3090'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_obj.get_device_name('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65358fa4-c4f0-4b1e-aaea-3dde05ce6a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 3060'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_obj.get_device_name('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "397ff9ee-5b40-41fd-a5d8-2ba5b5aea2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe47eca0-19d1-4641-83c6-8f064491f303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e3fa46d-6297-4720-9485-e200b021ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cfafc44-8eca-4c3c-99d2-e0ce4b81d698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 3090'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_obj.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09c2dc3a-da08-4595-adfd-aa5a67843744",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ade9e077-f2d7-4acc-9f24-f95429dd84ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 3060'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_obj.get_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e334a6f5-fd9e-4d0a-8a96-f8124b9b9ddb",
   "metadata": {},
   "source": [
    "#### Define the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5070ab1-6f69-4cc1-a6b0-710764028e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86077ab3-a4aa-41e9-9290-3384175a6e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf9e4315-8ae9-461e-bcbb-2a4eec5ba0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([4], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f55f030-a761-4f29-840f-9bdadc47ac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#### Model Layers\n",
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa0cd75c-5c7e-43b3-bd62-278d3798893a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63051ec4-8559-44a8-b708-1f59cacc53d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42b66496-e692-4d7f-8df8-ad7d843a53c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[ 0.1586, -0.2399, -0.3205, -0.4057, -0.2438, -0.4419, -0.2187,  0.4612,\n",
      "          0.1095,  0.0542, -0.2630, -0.0433,  0.1428, -0.2556, -0.1149,  0.3500,\n",
      "         -0.3799, -0.1457,  0.0826, -0.6201],\n",
      "        [-0.1320, -0.1106,  0.1164, -0.1295, -0.2179, -0.1809, -0.2783,  0.1757,\n",
      "          0.1932,  0.2960,  0.1485,  0.0652,  0.0202,  0.0042, -0.3440,  0.4649,\n",
      "          0.1074, -0.2309,  0.2906, -0.3376],\n",
      "        [ 0.2383,  0.0151, -0.3839, -0.1730, -0.2956, -0.5519, -0.2498,  0.1869,\n",
      "          0.1992,  0.3229,  0.0347,  0.3011, -0.1997, -0.0168, -0.1435,  0.3267,\n",
      "         -0.0894, -0.3672,  0.0442, -0.2774]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.1586, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4612, 0.1095,\n",
      "         0.0542, 0.0000, 0.0000, 0.1428, 0.0000, 0.0000, 0.3500, 0.0000, 0.0000,\n",
      "         0.0826, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1164, 0.0000, 0.0000, 0.0000, 0.0000, 0.1757, 0.1932,\n",
      "         0.2960, 0.1485, 0.0652, 0.0202, 0.0042, 0.0000, 0.4649, 0.1074, 0.0000,\n",
      "         0.2906, 0.0000],\n",
      "        [0.2383, 0.0151, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1869, 0.1992,\n",
      "         0.3229, 0.0347, 0.3011, 0.0000, 0.0000, 0.0000, 0.3267, 0.0000, 0.0000,\n",
      "         0.0442, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d572e8-2632-4fbe-a456-257b363cb07f",
   "metadata": {},
   "source": [
    "- nn.Sequential은 모듈의 정렬된 컨테이너입니다. 데이터는 정의된 것과 동일한 순서로 모든 모듈을 통과합니다. 순차 컨테이너를 사용하여 seq_modules와 같은 빠른 네트워크를 구성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "121f8d8b-0409-416e-b314-83491c6365f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3028c1-3da9-4263-aa68-a2f787dbb284",
   "metadata": {},
   "source": [
    "- 신경망의 마지막 선형 레이어는 nn으로 전달되는 로짓([-infty, infty]의 원시 값)을 반환합니다.소프트맥스 모듈. 로짓은 각 클래스에 대한 모형의 예측 확률을 나타내는 값[0, 1]으로 척도화됩니다. dim 매개 변수는 값이 1이 되어야 하는 차원을 나타냅니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dde6fd7e-1d7b-46e2-be04-105755985116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1247, 0.1029, 0.0778, 0.1058, 0.1054, 0.0879, 0.1248, 0.0768, 0.0864,\n",
       "         0.1076],\n",
       "        [0.1159, 0.0958, 0.0806, 0.1094, 0.1149, 0.0940, 0.1275, 0.0816, 0.0734,\n",
       "         0.1069],\n",
       "        [0.1091, 0.0980, 0.0880, 0.1083, 0.1074, 0.0903, 0.1181, 0.0834, 0.0842,\n",
       "         0.1132]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "pred_probab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05d635b-8081-42bb-9ead-29c57b747d51",
   "metadata": {},
   "source": [
    "#### Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc57b178-977f-4b9f-b1f4-765a4823beb9",
   "metadata": {},
   "source": [
    "- 신경망 내부의 많은 계층은 매개 변수화된다. 즉, 훈련 중에 최적화된 관련 가중치와 편향을 가지고 있다. 하위 분류 n.모듈은 모델 객체 내부에 정의된 모든 필드를 자동으로 추적하고 모델의 매개변수() 또는 named_parameters() 방법을 사용하여 모든 매개변수에 액세스할 수 있도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f385253-f085-411b-92a9-085e2a65ea9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0103,  0.0097, -0.0116,  ..., -0.0295,  0.0299, -0.0343],\n",
      "        [ 0.0320,  0.0030,  0.0079,  ..., -0.0068, -0.0049,  0.0316]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0254,  0.0159], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0250,  0.0111, -0.0247,  ...,  0.0314, -0.0107,  0.0110],\n",
      "        [-0.0021, -0.0035,  0.0362,  ...,  0.0081,  0.0074, -0.0412]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0035, 0.0126], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0338, -0.0286, -0.0232,  ..., -0.0206,  0.0050, -0.0274],\n",
      "        [-0.0034,  0.0034, -0.0272,  ..., -0.0192, -0.0025, -0.0234]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0306, -0.0194], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fc03b1-7e3a-4ea1-bd82-f9247e609263",
   "metadata": {},
   "source": [
    "#### AUTOMATIC DIFFERENTIATION WITH TORCH.AUTOGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796c225b-7421-479d-875e-01e6dd600612",
   "metadata": {},
   "source": [
    "- 신경망을 훈련할 때 가장 자주 사용되는 알고리즘은 후방 전파다. 이 알고리즘에서 매개 변수(모델 가중치)는 주어진 매개 변수에 대해 손실 함수의 기울기에 따라 조정된다.\n",
    "- 이러한 구배를 계산하기 위해, 파이토치는 토치라고 불리는 내장된 차별화 엔진을 가지고 있다.오토그라드 그것은 모든 계산 그래프에 대한 그라데이션의 자동 계산을 지원한다.\n",
    "- 입력 x, 매개 변수 w와 b, 그리고 일부 손실 함수를 가진 가장 단순한 단일 계층 신경망을 고려해보자. 다음과 같은 방법으로 PyTorch에서 정의할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b327ad6-ba45-4ca2-91f4-3ff0cb4492ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42d95266-d188-45cc-81cf-513935bb9557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3783, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0817402-35a9-4843-89dd-c911a06c1a13",
   "metadata": {},
   "source": [
    "#### Tensors, Functions and Computational graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf10318-a939-4952-bfff-d9323375df50",
   "metadata": {},
   "source": [
    "![Computational_Graph](./images/image01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab564c8-6f8f-482f-991d-f21790afab6b",
   "metadata": {},
   "source": [
    "- 이 네트워크에서 w와 b는 매개 변수이며, 최적화해야 합니다. 따라서, 우리는 그러한 변수들에 대해 손실 함수의 기울기를 계산할 수 있어야 한다. 이를 위해, 우리는 텐서의 required_grad 속성을 설정한다.\n",
    "- 텐서를 생성할 때 또는 나중에 x.requires_grad_(True) 방법을 사용하여 requires_grad 값을 설정할 수 있습니다.\n",
    "- 계산 그래프를 구성하기 위해 텐서에 적용하는 함수는 사실 클래스 함수의 객체이다. 이 객체는 순방향으로 함수를 계산하는 방법과 역방향 전파 단계 동안 함수의 도함수를 계산하는 방법을 알고 있습니다.\n",
    "- 역방향 전파 함수에 대한 참조는 텐서의 grad_fn 속성에 저장된다. 기능에 대한 자세한 내용은 설명서를 참조하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05cc9866-be89-4f5e-98bb-d368dd9a62ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x7f4243b2c210>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward object at 0x7f40f494c850>\n"
     ]
    }
   ],
   "source": [
    "print('Gradient function for z =', z.grad_fn)\n",
    "print('Gradient function for loss =', loss.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96ede36-b20b-4e6c-9c30-fed30ce77397",
   "metadata": {},
   "source": [
    "#### Computing Gradients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23822de-7e4b-4bcf-b1e3-060e87b7bee8",
   "metadata": {},
   "source": [
    "- 신경망에서 매개 변수의 가중치를 최적화하려면 매개 변수에 대한 손실 함수의 도함수를 계산해야 한다\n",
    "- 즉, \\frac{\\partial loss}{\\partial w}가 필요하다. \n",
    "- ww loss​및 \\fracsible loss}{\\fracs b} bb loss​x와 y의 일부 고정 값 하에서. 이러한 도함수를 계산하기 위해, 우리는 loss.backward()라고 부르고, w.grad와 b.grad에서 값을 검색한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "924ba87b-6a3f-4957-bdfb-07900206cdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1337, 0.3231, 0.0441],\n",
      "        [0.1337, 0.3231, 0.0441],\n",
      "        [0.1337, 0.3231, 0.0441],\n",
      "        [0.1337, 0.3231, 0.0441],\n",
      "        [0.1337, 0.3231, 0.0441]])\n",
      "tensor([0.1337, 0.3231, 0.0441])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1455e641-bb76-4735-82c5-1caefca257f9",
   "metadata": {},
   "source": [
    "- 계산 그래프의 리프 노드에 대한 grad 속성만 얻을 수 있으며, required_grad 속성이 True로 설정되어 있다. 그래프의 다른 모든 노드의 경우 그레이디언트를 사용할 수 없다.\n",
    "- 성능상의 이유로 주어진 그래프에서 뒤로 한 번만 사용하여 그레이디언트 계산을 수행할 수 있다. 동일한 그래프에서 여러 개의 역방향 호출을 수행해야 하는 경우 retain_graph=True를 역방향 호출로 전달해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e6d070-8cfd-4cca-962e-a923d4ff9b27",
   "metadata": {},
   "source": [
    "#### Disabling Gradient Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10098ede-cea0-40b2-bd49-2ff82928e824",
   "metadata": {},
   "source": [
    "- 기본적으로 required_grad=True인 모든 텐서는 계산 기록을 추적하고 구배 계산을 지원합니다.\n",
    "- 그러나, 예를 들어 모델을 훈련하고 일부 입력 데이터에 적용하려고 할 때, 즉 네트워크를 통해 전진 계산만 수행하고자 할 때, 그렇게 할 필요가 없는 경우가 있다. 계산 코드를 torch.no_gradsec 블록으로 둘러서 계산 추적을 중지할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "747e115a-5659-4f0d-8ed0-3b0ba39f567d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eff0b00a-2216-4f51-b559-2a935e9158a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d60ba44b-317b-4ece-809d-3bef8a86beb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4009,  3.4491, -1.8808])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1db1222-c338-46c3-9b42-292de26fccbf",
   "metadata": {},
   "source": [
    "- 동일한 결과를 얻는 또 다른 방법은 텐서에 분리() 방법을 사용하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fdfe977-2ba4-47ac-8095-472208e302ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0697fbc8-b732-47aa-81ee-1fca7c51aed1",
   "metadata": {},
   "source": [
    "- 그라데이션 추적을 비활성화할 수 있는 이유는 다음과 같습니다.\n",
    "  - 신경망의 일부 파라미터를 고정된 파라미터로 표시합니다. 이것은 사전 훈련된 네트워크를 미세 조정하는 매우 일반적인 시나리오이다.\n",
    "  - 그레이디언트를 추적하지 않는 텐서의 계산이 더 효율적이기 때문에 전진 패스만 할 때 계산 속도를 높입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b845568c-50ce-49ec-ad42-5d5201ad282c",
   "metadata": {},
   "source": [
    "#### More on Computational Graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b286a305-04fe-4b35-9217-0bb7b0a959d3",
   "metadata": {},
   "source": [
    "- 개념적으로, autograd는 Function 객체로 구성된 DAG(Directed Acyclic Graph)에 데이터(텐서) 및 모든 실행 작업(결과적인 새 텐서) 기록을 유지한다. 이 DAG에서 리프는 입력 텐서이고 루트는 출력 텐서이다. 이 그래프를 뿌리부터 잎까지 추적하면 체인 규칙을 사용하여 자동으로 그라데이션이 계산됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d7ef77-c324-4158-9542-4eaf743e29a8",
   "metadata": {},
   "source": [
    "- 전진 패스에서 오토그라드는 두 가지 작업을 동시에 수행합니다.\n",
    "  - 결과 텐서를 계산하기 위해 요청된 작업을 실행합니다.\n",
    "  - DAG에서 작업의 그라데이션 기능을 유지합니다.\n",
    "- DAG 루트에서 .backward()가 호출되면 백워드 패스가 시작됩니다. 그러면 autograd:\n",
    "  - 각 .grad_fn에서 구배를 계산합니다\n",
    "  - 각 텐서의 .grad 속성에 누적한다.\n",
    "  - 체인 규칙을 사용하면 리프 텐서까지 전파됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d59942-4b62-4123-af29-995414743525",
   "metadata": {},
   "source": [
    "#### Optional Reading: Tensor Gradients and Jacobian Products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0fca97-d8c5-4641-9dfd-ad0aeef270aa",
   "metadata": {},
   "source": [
    "- 많은 경우, 우리는 스칼라 손실 함수를 가지고 있으며, 우리는 일부 매개 변수에 대해 기울기를 계산해야 한다. 그러나 출력 함수가 임의의 텐서인 경우가 있다. 이 경우 PyTorch를 사용하면 실제 기울기가 아니라 소위 야코비안 곱(https://www.youtube.com/watch?v=XF44_HAMnKY)을 계산할 수 있습니다 \n",
    "- Jacobian 행렬 자체를 계산하는 대신 PyTorch를 사용하면 Jacobian 곱 v^T\\cdot Jv를 계산할 수 있습니다. t 주어진 입력 벡터 v=(v_1 \\dump v_m)v=(v)에 대한 ΔJ 1​…v m​).\n",
    "- 이는 vv를 인수로 하여 역방향으로 호출함으로써 달성된다. vv의 크기는 곱을 계산하고자 하는 원래 텐서의 크기와 같아야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61712004-25e1-4560-b2ca-b7b4e3b71bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.eye(5, requires_grad=True)\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46a9c076-8107-4db4-8272-2db73f6f141a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1., 1., 1., 1.],\n",
       "        [1., 4., 1., 1., 1.],\n",
       "        [1., 1., 4., 1., 1.],\n",
       "        [1., 1., 1., 4., 1.],\n",
       "        [1., 1., 1., 1., 4.]], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = (inp+1).pow(2)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c77fe7a-aa0d-4df1-b5ab-5babc9d94a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1., 1., 1., 1.],\n",
       "        [1., 4., 1., 1., 1.],\n",
       "        [1., 1., 4., 1., 1.],\n",
       "        [1., 1., 1., 4., 1.],\n",
       "        [1., 1., 1., 1., 4.]], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7aef6c40-ded3-40e8-b2bc-986a71aedf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call\n",
      " tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"First call\\n\", inp.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dab39720-7b46-4219-b705-b5032cf9988a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1., 1., 1., 1.],\n",
       "        [1., 4., 1., 1., 1.],\n",
       "        [1., 1., 4., 1., 1.],\n",
       "        [1., 1., 1., 4., 1.],\n",
       "        [1., 1., 1., 1., 4.]], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "853cea9d-89fe-4342-a8a0-d87078445f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Second call\n",
      " tensor([[8., 4., 4., 4., 4.],\n",
      "        [4., 8., 4., 4., 4.],\n",
      "        [4., 4., 8., 4., 4.],\n",
      "        [4., 4., 4., 8., 4.],\n",
      "        [4., 4., 4., 4., 8.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSecond call\\n\", inp.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "674231f0-7b2a-46eb-9582-c817475f6059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.grad.zero_()\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a38732e1-96f6-462b-a7e4-d2e96bfe9d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1., 1., 1., 1.],\n",
       "        [1., 4., 1., 1., 1.],\n",
       "        [1., 1., 4., 1., 1.],\n",
       "        [1., 1., 1., 4., 1.],\n",
       "        [1., 1., 1., 1., 4.]], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4864e74e-74c5-4dd6-9abf-d31f0e465bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call after zeroing gradients\n",
      " tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCall after zeroing gradients\\n\", inp.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98fc2d8-ec88-413a-995c-55a9504929dd",
   "metadata": {},
   "source": [
    "- 같은 인수를 사용하여 두 번째로 뒤로 호출할 때 그라디언트 값이 다릅니다. 이것은 역방향 전파를 수행할 때 PyTorch가 그라디언트를 축적하기 때문에 발생합니다. 계산된 그래디언트의 값은 계산 그래프의 모든 리프 노드의 그래드 특성에 추가됩니다. 적절한 그라데이션을 계산하려면 이전에 그라데이션 속성을 제로화해야 합니다. 실제 훈련에서 옵티마이저는 우리가 이것을 할 수 있도록 도와줍니다.\n",
    "- 이전에는 매개 변수 없이 역방향() 함수를 호출했습니다. 이는 본질적으로 신경망 훈련 중 손실과 같은 스칼라 값 함수의 경우 기울기를 계산하는 유용한 방법인 백워드(토치.텐서(1.0) 호출과 동일하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f143e41-c35b-4b9f-9b67-c9b7501ab81c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
